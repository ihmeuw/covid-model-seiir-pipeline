{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cba75f-ef8e-48e8-a1c5-efacfda6d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple, Dict\n",
    "from pathlib import Path\n",
    "import functools\n",
    "import yaml\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from covid_model_seiir_pipeline.pipeline.fit.specification import FitSpecification\n",
    "from covid_model_seiir_pipeline.pipeline.fit.data import FitDataInterface\n",
    "from covid_model_seiir_pipeline.lib import (\n",
    "    cli_tools,\n",
    "    parallel,\n",
    ")\n",
    "\n",
    "LOGGER = cli_tools.task_performance_logger\n",
    "\n",
    "sns.set_style('white_grid')\n",
    "\n",
    "NUM_CORES = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bd507b7-02f2-4479-9085-38ff070277f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(fit_version: str, variants: List[str]) -> Tuple[pd.Index, int]:\n",
    "    specification = FitSpecification.from_version_root(fit_version)\n",
    "    data_interface = FitDataInterface.from_specification(specification)\n",
    "\n",
    "    hierarchy = data_interface.load_hierarchy('pred')\n",
    "    location_ids = hierarchy.loc[hierarchy['most_detailed'] == 1, 'location_id'].to_list()\n",
    "\n",
    "    date_start = data_interface.load_reported_epi_data().reset_index()['date'].min()\n",
    "    date_start -= pd.Timedelta(days=30)\n",
    "    date_end = data_interface.load_reported_epi_data().reset_index()['date'].max()\n",
    "    date_end += pd.Timedelta(days=30)\n",
    "    dates = pd.date_range(date_start, date_end)\n",
    "\n",
    "    universal_idx = pd.MultiIndex.from_product([location_ids, dates, variants],\n",
    "                                               names=['location_id', 'date', 'variant'])\n",
    "\n",
    "    n_draws = data_interface.get_n_draws()\n",
    "\n",
    "    return universal_idx, n_draws\n",
    "\n",
    "\n",
    "def load_fit_draw_infections(draw_id: int, measure: str, data_interface: FitDataInterface,\n",
    "                             variants: List[str], universal_idx: pd.Index) -> pd.Series:\n",
    "    # have to change renaming logic if this pattern changes\n",
    "    columns = [f'Infection_all_{variant}_all_lr' for variant in variants] \\\n",
    "               + [f'Infection_all_{variant}_all_hr' for variant in variants]\n",
    "    if measure != 'final':\n",
    "        columns += ['round']\n",
    "\n",
    "    data = data_interface.load_compartments(draw_id, measure_version=measure, columns=columns)\n",
    "    if 'round' in data:\n",
    "        data = data.loc[data['round'] == 2].drop('round', axis=1)\n",
    "    data = data.rename(columns={col: col.split('_all_')[1] for col in data})\n",
    "    data = data.groupby(data.columns, axis=1).sum(min_count=1)\n",
    "    data = data.groupby('location_id').diff()\n",
    "    data = pd.melt(data, ignore_index=False, var_name='variant', value_name=f'draw_{draw_id}')\n",
    "    data = data.set_index('variant', append=True).sort_index()\n",
    "\n",
    "    return data.reindex(universal_idx)\n",
    "\n",
    "\n",
    "def load_counterfactual_draw_infections(draw_id: int, counterfactual_version: Path,\n",
    "                                        variants: List[str], universal_idx: pd.Index) -> pd.Series:\n",
    "    data = pd.read_parquet(counterfactual_version / 'raw_outputs' / f'draw_{draw_id}.parquet',\n",
    "                           columns=[f'modeled_infections_{variant}' for variant in variants])\n",
    "    data = data.rename(columns={col: col.replace('modeled_infections_', '') for col in data.columns})\n",
    "    data = pd.melt(data, ignore_index=False,\n",
    "                   var_name='variant', value_name=f'draw_{draw_id}')\n",
    "    data = data.set_index('variant', append=True)\n",
    "\n",
    "    return data.reindex(universal_idx)\n",
    "\n",
    "\n",
    "def load_infections(version: str, source: str, measure: str,  variants: List[str],\n",
    "                    universal_idx: pd.Index, n_draws: int) -> pd.DataFrame:\n",
    "    LOGGER.info(f'Reading infections from {version} ({measure})')\n",
    "    if source == 'fit':\n",
    "        specification = FitSpecification.from_version_root(version)\n",
    "        data_interface = FitDataInterface.from_specification(specification)\n",
    "        _load_draw_infections = functools.partial(load_fit_draw_infections,\n",
    "                                                  measure=measure,\n",
    "                                                  data_interface=data_interface,\n",
    "                                                  variants=variants,\n",
    "                                                  universal_idx=universal_idx)\n",
    "    elif source == 'counterfactual':\n",
    "        _load_draw_infections = functools.partial(load_counterfactual_draw_infections,\n",
    "                                                  counterfactual_version=Path(version) / measure,\n",
    "                                                  variants=variants,\n",
    "                                                  universal_idx=universal_idx)\n",
    "    infections = parallel.run_parallel(\n",
    "        runner=_load_draw_infections,\n",
    "        arg_list=range(n_draws),\n",
    "        num_cores=NUM_CORES,\n",
    "        progress_bar=True,\n",
    "    )\n",
    "    infections = pd.concat(infections, axis=1)\n",
    "    \n",
    "    return infections\n",
    "\n",
    "\n",
    "def load_draw_sero_points(draw_id: int, measure: str, data_interface: FitDataInterface) -> pd.Series:\n",
    "    sero_points = data_interface.load_final_seroprevalence(draw_id,\n",
    "                                                           measure_version=measure,\n",
    "                                                           columns=['location_id', 'sero_date', 'is_outlier'])\n",
    "    sero_points['date'] = sero_points['sero_date'] - pd.Timedelta(days=14)\n",
    "    sero_points = sero_points.loc[sero_points['is_outlier'] == 0]\n",
    "    sero_points[f'draw_{draw_id}'] = 1\n",
    "    sero_points = (sero_points\n",
    "                   .groupby(['location_id', 'date'])[f'draw_{draw_id}'].sum())\n",
    "\n",
    "    return sero_points\n",
    "\n",
    "\n",
    "def load_sero_points(fit_version: str, measure: str, n_draws: int) -> List[int]:\n",
    "    LOGGER.info(f'Reading sero locations from {fit_version}')\n",
    "    specification = FitSpecification.from_version_root(fit_version)\n",
    "    data_interface = FitDataInterface.from_specification(specification)\n",
    "    _load_draw_sero_points = functools.partial(load_draw_sero_points,\n",
    "                                               measure=measure,\n",
    "                                               data_interface=data_interface)\n",
    "    sero_points = parallel.run_parallel(\n",
    "        runner=_load_draw_sero_points,\n",
    "        arg_list=range(n_draws),\n",
    "        num_cores=NUM_CORES,\n",
    "        progress_bar=True,\n",
    "    )\n",
    "    sero_points = pd.concat(sero_points, axis=1).max(axis=1).rename('n')\n",
    "    \n",
    "    return sero_points\n",
    "\n",
    "\n",
    "def compile_inputs(reference_version: str, comparator_version: str, variants: List[str]) -> Tuple[Dict, Dict]:\n",
    "    universal_idx, n_draws = create_index(comparator_version, variants)\n",
    "\n",
    "    reference_infections = {}\n",
    "    comparator_infections = {}\n",
    "    for measure in ['case', 'admission', 'death']:\n",
    "        reference_infections[measure] = load_infections(reference_version,\n",
    "                                                        'counterfactual', measure, variants,\n",
    "                                                        universal_idx, n_draws)\n",
    "        comparator_infections[measure] = load_infections(comparator_version,\n",
    "                                                         'fit', measure, variants,\n",
    "                                                         universal_idx, n_draws)\n",
    "\n",
    "    infections_locations = universal_idx.get_level_values('location_id').unique().to_list()\n",
    "    sero_points = load_sero_points(comparator_version, measure, n_draws)\n",
    "    sero_locations = sero_points.index.get_level_values('location_id').unique().to_list()\n",
    "    overlap = [l for l in sero_locations if l in infections_locations]\n",
    "    sero_points = sero_points.loc[overlap]\n",
    "\n",
    "    return reference_infections, comparator_infections, sero_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "375ec739-c9a7-47cf-ae10-64f406a73789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_relative_error(reference_infections: pd.DataFrame,\n",
    "                             comparator_infections: pd.DataFrame,\n",
    "                             units: str):\n",
    "    comparator_infections = (comparator_infections\n",
    "                             .where(comparator_infections >= 0)\n",
    "                             .replace(np.inf, np.nan)\n",
    "                             .dropna(how='all')) + 0.1\n",
    "    reference_infections = (reference_infections\n",
    "                            .where(reference_infections >= 0)\n",
    "                            .replace(np.inf, np.nan)\n",
    "                            .dropna(how='all')) + 0.1\n",
    "    idx = comparator_infections.index.intersection(reference_infections.index)\n",
    "\n",
    "    comparator_infections = comparator_infections.loc[idx]\n",
    "    reference_infections = reference_infections.loc[idx]\n",
    "    comparator_infections = comparator_infections.where(reference_infections >= 0)\n",
    "    reference_infections = reference_infections.where(comparator_infections >= 0)\n",
    "\n",
    "    if units == 'global_draws':\n",
    "        relative_error = comparator_infections.loc[idx].sum() / reference_infections.loc[idx].sum()\n",
    "    elif units == 'global_mean':\n",
    "        relative_error = (comparator_infections.loc[idx].sum() \\\n",
    "                          / reference_infections.loc[idx].sum()).mean(axis=1)\n",
    "    elif units == 'global_median':\n",
    "        relative_error = (comparator_infections.loc[idx].sum() \\\n",
    "                          / reference_infections.loc[idx].sum()).median(axis=1)\n",
    "    elif units == 'location_draws':\n",
    "        relative_error = comparator_infections.loc[idx].groupby('location_id').sum() \\\n",
    "                        / reference_infections.loc[idx].groupby('location_id').sum()\n",
    "    elif units == 'clipped_location_means':\n",
    "        relative_error = (comparator_infections.loc[idx].groupby('location_id').sum() \\\n",
    "                          / reference_infections.loc[idx].groupby('location_id').sum())\n",
    "        ## CLIP 2.5TH AND 97.5TH PERCENTILE\n",
    "        relative_error = relative_error.clip(\n",
    "            **dict(zip(['lower', 'upper'], np.quantile(relative_error, [0.025, 0.975], axis=1))),\n",
    "            axis=0,\n",
    "        ).mean(axis=1)\n",
    "    elif units == 'location_daily_medians':\n",
    "        # relative_error = (comparator_infections.loc[idx].groupby('location_id').sum() \\\n",
    "        #                   / reference_infections.loc[idx].groupby('location_id').sum()).median(axis=1)\n",
    "        relative_error = (comparator_infections.loc[idx].median(axis=1).groupby('location_id').sum() \\\n",
    "                          / reference_infections.loc[idx].median(axis=1).groupby('location_id').sum())\n",
    "\n",
    "    return relative_error\n",
    "\n",
    "\n",
    "def minimize_scaling(reference_infections: pd.DataFrame,\n",
    "                     comparator_infections: pd.DataFrame,\n",
    "                     sero_points: pd.Series,\n",
    "                     relative_error: pd.Series,\n",
    "                     N: int = 4):\n",
    "    max_infections = ((comparator_infections + reference_infections)\n",
    "                      .groupby('location_id')\n",
    "                      .cumsum()\n",
    "                      .max(axis=1)\n",
    "                      .dropna()\n",
    "                      .astype(bool))\n",
    "    variant_idx = max_infections.loc[max_infections].index\n",
    "\n",
    "    variant_sero_points = sero_points.loc[sero_points.index.intersection(variant_idx)].groupby('location_id').sum()\n",
    "    minimized_relative_error = 1 - (1 - relative_error) * (1 - variant_sero_points.clip(1, N) / N)\n",
    "    minimized_relative_error = minimized_relative_error.fillna(relative_error)\n",
    "\n",
    "    return minimized_relative_error\n",
    "\n",
    "\n",
    "def calculate_kappa_scalars(reference_infections: Dict[str, pd.DataFrame],\n",
    "                            comparator_infections: Dict[str, pd.DataFrame],\n",
    "                            sero_points: pd.Series,\n",
    "                            variants: str,\n",
    "                            units: str,\n",
    "                            minimize_variants: List[str],\n",
    "                            infections_threshold: int,):\n",
    "    relative_error = {}\n",
    "    for variant in variants:\n",
    "        LOGGER.info(variant)\n",
    "        relative_error[variant] = {}\n",
    "        for measure in ['case', 'admission', 'death']:\n",
    "            ref = reference_infections[measure].loc[:, :, variant].reset_index('variant', drop=True)\n",
    "            comp = comparator_infections[measure].loc[:, :, variant].reset_index('variant', drop=True)\n",
    "            over_threshold = comp.groupby('location_id').sum().mean(axis=1) > infections_threshold\n",
    "            over_threshold_locations = over_threshold.loc[over_threshold].index\n",
    "            comp = comp.loc[over_threshold_locations]\n",
    "            _relative_error = calculate_relative_error(\n",
    "                ref, comp,\n",
    "                units\n",
    "            )\n",
    "            if variant in minimize_variants:\n",
    "                _relative_error = minimize_scaling(\n",
    "                    ref, comp,\n",
    "                    sero_points,\n",
    "                    _relative_error\n",
    "                )\n",
    "            relative_error[variant][measure] = _relative_error # .loc[_relative_error != 1.].to_dict()\n",
    "    return relative_error\n",
    "\n",
    "\n",
    "def store_kappa_scalars(relative_error: pd.DataFrame, variants: List[str]):\n",
    "    for variant in variants:\n",
    "        variant_relative_error_dict = {\n",
    "            measure: measure_scalars.to_dict()\n",
    "            for measure, measure_scalars in kappa_scalars[variant].items()\n",
    "        }\n",
    "        with open(f'../../pipeline/fit/model/kappa_scaling_factors/{variant}.yaml',\n",
    "                  'w') as file:\n",
    "            yaml.dump(variant_relative_error_dict, file, default_flow_style=False)\n",
    "\n",
    "\n",
    "def make_histograms(relative_error: Dict, variants: str, sero_locations: List[int] = None,):\n",
    "    measures = ['case', 'admission', 'death']\n",
    "    fig, ax = plt.subplots(3, len(variants), figsize=(5 * len(variants), 15), sharex='col')\n",
    "    summary = {}\n",
    "    for ii, variant in enumerate(variants):\n",
    "        _summary = {}\n",
    "        for i, measure in enumerate(measures):\n",
    "            if len(variants) > 1:\n",
    "                plot_idx = i, ii\n",
    "            else:\n",
    "                plot_idx = i\n",
    "            # _relative_error = np.array(list(relative_error[variant][measure].values()))\n",
    "            # bins = 20\n",
    "            _relative_error = relative_error[variant][measure].copy()\n",
    "            if sero_locations[variant]:\n",
    "                _relative_error = _relative_error.query(\n",
    "                    f'location_id in [{\",\".join([str(sero_location) for sero_location in sero_locations[variant]])}]'\n",
    "                )\n",
    "            _relative_error = _relative_error.where(_relative_error != 1.0)\n",
    "            n_locs = _relative_error.index.get_level_values('location_id').unique().size\n",
    "            _relative_error = np.hstack(_relative_error.values.tolist())\n",
    "            _relative_error = _relative_error[~np.isnan(_relative_error)]\n",
    "            _relative_error = np.log(_relative_error)\n",
    "            bins = 40\n",
    "            ax[plot_idx].hist(_relative_error.clip(*np.quantile(_relative_error, [0.05, 0.95])),\n",
    "                           bins=bins)\n",
    "            ax[plot_idx].axvline(np.median(_relative_error), linestyle=':', color='red')\n",
    "            ax[plot_idx].axvline(np.mean(_relative_error), linestyle=':', color='forestgreen')\n",
    "            for q in np.quantile(_relative_error, [0.25, 0.75]):\n",
    "                ax[plot_idx].axvline(q, linestyle='--', color='red')\n",
    "            if i == 0:\n",
    "                ax[plot_idx].set_title(variant)\n",
    "            if ii == 0:\n",
    "                ax[plot_idx].set_ylabel(measure)\n",
    "            ax[plot_idx].set_title(f'n={n_locs}')\n",
    "            _summary[measure] = [np.quantile(np.exp(_relative_error), 0.25),\n",
    "                                 np.quantile(np.exp(_relative_error), 0.50),\n",
    "                                 np.exp(np.mean(_relative_error)),\n",
    "                                 np.quantile(np.exp(_relative_error), 0.75)]\n",
    "        summary[variant] = pd.DataFrame(_summary,\n",
    "                                        index=pd.Index(['p25', 'p50', 'geom_mean', 'p75'])).T\n",
    "        fig.tight_layout()\n",
    "        fig.show()\n",
    "        \n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d1b31e1-481f-4c08-a39b-47f12c15bb04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 23:53:16.987 | INFO     | covid_model_seiir_pipeline.lib.cli_tools.performance_logger.performance_logger:info:26 - Generating infections\n",
      "2022-12-13 23:53:18.343 | INFO     | covid_model_seiir_pipeline.lib.cli_tools.performance_logger.performance_logger:info:26 - Reading infections from /mnt/share/covid-19/seir-counterfactual/2022_12_13.01 (case)\n",
      "100%|█████████████████████████████████████████| 100/100 [00:20<00:00,  4.91it/s]\n",
      "2022-12-13 23:53:48.516 | INFO     | covid_model_seiir_pipeline.lib.cli_tools.performance_logger.performance_logger:info:26 - Reading infections from /mnt/share/covid-19/seir-fit/2022_12_13.02 (case)\n",
      "100%|█████████████████████████████████████████| 100/100 [00:20<00:00,  4.80it/s]\n",
      "2022-12-13 23:54:18.658 | INFO     | covid_model_seiir_pipeline.lib.cli_tools.performance_logger.performance_logger:info:26 - Reading infections from /mnt/share/covid-19/seir-counterfactual/2022_12_13.01 (admission)\n",
      "100%|█████████████████████████████████████████| 100/100 [00:18<00:00,  5.27it/s]\n",
      "2022-12-13 23:54:46.831 | INFO     | covid_model_seiir_pipeline.lib.cli_tools.performance_logger.performance_logger:info:26 - Reading infections from /mnt/share/covid-19/seir-fit/2022_12_13.02 (admission)\n",
      "100%|█████████████████████████████████████████| 100/100 [00:19<00:00,  5.03it/s]\n",
      "2022-12-13 23:55:15.771 | INFO     | covid_model_seiir_pipeline.lib.cli_tools.performance_logger.performance_logger:info:26 - Reading infections from /mnt/share/covid-19/seir-counterfactual/2022_12_13.01 (death)\n",
      "100%|█████████████████████████████████████████| 100/100 [00:19<00:00,  5.16it/s]\n",
      "2022-12-13 23:55:44.189 | INFO     | covid_model_seiir_pipeline.lib.cli_tools.performance_logger.performance_logger:info:26 - Reading infections from /mnt/share/covid-19/seir-fit/2022_12_13.02 (death)\n",
      "100%|█████████████████████████████████████████| 100/100 [00:20<00:00,  4.86it/s]\n",
      "2022-12-13 23:56:14.085 | INFO     | covid_model_seiir_pipeline.lib.cli_tools.performance_logger.performance_logger:info:26 - Reading sero locations from /mnt/share/covid-19/seir-fit/2022_12_13.02\n",
      "100%|████████████████████████████████████████| 100/100 [00:00<00:00, 570.47it/s]\n"
     ]
    }
   ],
   "source": [
    "##################################\n",
    "## GLOBAL -- 2022 VARIANTS ONLY ##\n",
    "##################################\n",
    "\n",
    "# # ancestral, alpha, beta, gamma, and delta scalars applied\n",
    "# reference_version = '/mnt/share/covid-19/seir-counterfactual/2022_10_19.01'\n",
    "# comparator_version = '/mnt/share/covid-19/seir-fit/2022_10_19.03'\n",
    "# variants = ['omicron']\n",
    "# RUN = 'GLOBAL'\n",
    "\n",
    "# # ancestral, alpha, beta, gamma, delta, and omicron scalars applied\n",
    "# reference_version = '/mnt/share/covid-19/seir-counterfactual/2022_10_19.02'\n",
    "# comparator_version = '/mnt/share/covid-19/seir-fit/2022_10_19.11'\n",
    "# variants = ['ba5']\n",
    "# RUN = 'GLOBAL'\n",
    "\n",
    "#################################\n",
    "## LOCAL -- 2022 VARIANTS ONLY ##\n",
    "#################################\n",
    "\n",
    "# # ancestral, alpha, beta, gamma, and delta scalars applied\n",
    "# reference_version = '/mnt/share/covid-19/seir-counterfactual/2022_10_19.04'\n",
    "# comparator_version = '/mnt/share/covid-19/seir-fit/2022_10_19.13'\n",
    "# variants = ['omicron']\n",
    "# RUN = 'LOCAL'\n",
    "\n",
    "## DAILY MEDIAN OMICRON\n",
    "# # ancestral, alpha, beta, gamma, delta, and omicron scalars applied\n",
    "# reference_version = '/mnt/share/covid-19/seir-counterfactual/2022_10_19.06'\n",
    "# comparator_version = '/mnt/share/covid-19/seir-fit/2022_10_19.16'\n",
    "# variants = ['ba5']\n",
    "# RUN = 'LOCAL'\n",
    "\n",
    "## CLIPPED MEAN RATIO OMICRON\n",
    "# # ancestral, alpha, beta, gamma, delta, and omicron scalars applied\n",
    "# reference_version = '/mnt/share/covid-19/seir-counterfactual/2022_10_20.02'\n",
    "# comparator_version = '/mnt/share/covid-19/seir-fit/2022_10_20.03'\n",
    "# variants = ['ba5']\n",
    "# RUN = 'LOCAL'\n",
    "\n",
    "###########################\n",
    "## LOCAL -- ALL VARIANTS ##\n",
    "###########################\n",
    "\n",
    "# # ancestral scalars applied\n",
    "# reference_version = '/mnt/share/covid-19/seir-counterfactual/2022_10_19.03'\n",
    "# comparator_version = '/mnt/share/covid-19/seir-fit/2022_10_19.12'\n",
    "# variants = ['alpha', 'beta', 'gamma']\n",
    "# RUN = 'LOCAL'\n",
    "\n",
    "## DAILY MEDIAN ALPHA/BETA/GAMMA\n",
    "# # ancestral, alpha, beta, and gamma scalars applied\n",
    "# reference_version = '/mnt/share/covid-19/seir-counterfactual/2022_10_19.05'\n",
    "# comparator_version = '/mnt/share/covid-19/seir-fit/2022_10_19.15'\n",
    "# variants = ['delta']\n",
    "# RUN = 'LOCAL'\n",
    "\n",
    "# # ancestral, alpha, beta, gamma, and delta scalars applied\n",
    "# reference_version = '/mnt/share/covid-19/seir-counterfactual/2022_10_20.01'\n",
    "# comparator_version = '/mnt/share/covid-19/seir-fit/2022_10_19.17'\n",
    "# variants = ['omicron']\n",
    "# RUN = 'LOCAL'\n",
    "\n",
    "# # ancestral, alpha, beta, gamma, delta, and omicron scalars applied\n",
    "# reference_version = '/mnt/share/covid-19/seir-counterfactual/2022_10_20.06'\n",
    "# comparator_version = '/mnt/share/covid-19/seir-fit/2022_10_20.08'\n",
    "# variants = ['ba5']\n",
    "# RUN = 'LOCAL'\n",
    "\n",
    "# ##################################################\n",
    "# # PROD 2022-11-14 UPDATE\n",
    "# ##################################################\n",
    "# # ancestral, alpha, beta, gamma, delta, and omicron scalars applied\n",
    "# reference_version = '/mnt/share/covid-19/seir-counterfactual/2022_11_16.04'\n",
    "# comparator_version = '/mnt/share/covid-19/seir-fit/2022_11_16.03'\n",
    "# variants = ['ba5']\n",
    "# RUN = 'LOCAL'\n",
    "# ##################################################\n",
    "\n",
    "##################################################\n",
    "# PROD 2022-12-12 UPDATE\n",
    "##################################################\n",
    "# ancestral, alpha, beta, gamma, delta, and omicron scalars applied\n",
    "reference_version = '/mnt/share/covid-19/seir-counterfactual/2022_12_13.01'\n",
    "comparator_version = '/mnt/share/covid-19/seir-fit/2022_12_13.02'\n",
    "variants = ['ba5']\n",
    "RUN = 'LOCAL'\n",
    "##################################################\n",
    "\n",
    "## CLIPPED MEAN RATIO ALPHA/BETA/GAMMA\n",
    "# # ancestral, alpha, beta, and gamma scalars applied\n",
    "# reference_version = '/mnt/share/covid-19/seir-counterfactual/2022_10_20.03'\n",
    "# comparator_version = '/mnt/share/covid-19/seir-fit/2022_10_20.04'\n",
    "# variants = ['delta']\n",
    "# RUN = 'LOCAL'\n",
    "\n",
    "# # ancestral, alpha, beta, gamma, and delta scalars applied\n",
    "# reference_version = '/mnt/share/covid-19/seir-counterfactual/2022_10_20.04'\n",
    "# comparator_version = '/mnt/share/covid-19/seir-fit/2022_10_20.06'\n",
    "# variants = ['omicron']\n",
    "# RUN = 'LOCAL'\n",
    "\n",
    "# # ancestral, alpha, beta, gamma, delta, and omicron scalars applied\n",
    "# reference_version = '/mnt/share/covid-19/seir-counterfactual/2022_10_20.05'\n",
    "# comparator_version = '/mnt/share/covid-19/seir-fit/2022_10_20.07'\n",
    "# variants = ['ba5']\n",
    "# RUN = 'LOCAL'\n",
    "\n",
    "########################################################\n",
    "########################################################\n",
    "LOGGER.info('Generating infections')\n",
    "reference_infections, comparator_infections, sero_points = compile_inputs(\n",
    "    reference_version, comparator_version, variants\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe10ec6-52e3-46db-87e5-33ae1856416e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # reference_version = '/mnt/share/covid-19/seir-counterfactual/2022_10_20.05'\n",
    "# # comparator_version = '/mnt/share/covid-19/seir-fit/2022_10_20.07'\n",
    "# # variant = 'ba5'\n",
    "# # LOGGER.info('Generating infections')\n",
    "# # reference_infections, comparator_infections, sero_points = compile_inputs(\n",
    "# #     reference_version, comparator_version, [variant]\n",
    "# # )\n",
    "\n",
    "# measure = 'admission'\n",
    "# location_id = 60382\n",
    "\n",
    "# ref = reference_infections[measure].loc[:, '2021-10-01':, variant].reset_index('variant', drop=True)\n",
    "# comp = comparator_infections[measure].loc[:, '2021-10-01':, variant].reset_index('variant', drop=True)\n",
    "\n",
    "\n",
    "# _comp = (comp\n",
    "#          .where(comp >= 0)\n",
    "#          .replace(np.inf, np.nan)\n",
    "#          .dropna(how='all'))\n",
    "# _ref = (ref\n",
    "#         .where(ref >= 0)\n",
    "#         .replace(np.inf, np.nan)\n",
    "#         .dropna(how='all'))\n",
    "# _idx = _comp.index.intersection(_ref.index)\n",
    "\n",
    "\n",
    "# _comp = _comp.loc[_idx]\n",
    "# _ref = _ref.loc[_idx]\n",
    "# _comp = _comp.where(_ref >= 0)\n",
    "# _ref = _ref.where(_comp >= 0)\n",
    "\n",
    "\n",
    "# fig, ax = plt.subplots(1, 2, figsize=(16, 4.5))\n",
    "# ref.loc[_idx].loc[location_id].plot(ax=ax[0], color='darkgrey',\n",
    "#                                     alpha=0.1, legend=False)\n",
    "# comp.loc[_idx].loc[location_id].plot(ax=ax[0], color='dodgerblue',\n",
    "#                                     alpha=0.1, legend=False)\n",
    "# ref.loc[_idx].loc[location_id].mean(axis=1).plot(ax=ax[0], color='black')\n",
    "# comp.loc[_idx].loc[location_id].mean(axis=1).plot(ax=ax[0], color='navy')\n",
    "\n",
    "# ref.loc[_idx].loc[location_id].cumsum().plot(ax=ax[1], color='darkgrey',\n",
    "#                                     alpha=0.1, legend=False)\n",
    "# comp.loc[_idx].loc[location_id].cumsum().plot(ax=ax[1], color='dodgerblue',\n",
    "#                                     alpha=0.1, legend=False)\n",
    "# ref.loc[_idx].loc[location_id].cumsum().mean(axis=1).plot(ax=ax[1], color='black')\n",
    "# comp.loc[_idx].loc[location_id].cumsum().mean(axis=1).plot(ax=ax[1], color='navy')\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbd7ec4-ec80-4e12-99f6-84ce351d9f85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def clipped_mean(comparator_infections, reference_infections, idx, pctiles):\n",
    "#     relative_error = (comparator_infections.loc[idx].groupby('location_id').sum() \\\n",
    "#                               / reference_infections.loc[idx].groupby('location_id').sum())\n",
    "#     ## CLIP 2.5TH AND 97.5TH PERCENTILE\n",
    "#     relative_error = relative_error.clip(\n",
    "#         **dict(zip(['lower', 'upper'], np.quantile(relative_error, pctiles, axis=1))),\n",
    "#         axis=0,\n",
    "#     ).mean(axis=1)\n",
    "#     return relative_error\n",
    "\n",
    "# {\n",
    "#     'mean pre': (_comp.loc[_idx].mean(axis=1).groupby('location_id').sum() \\\n",
    "#                  / _ref.loc[_idx].mean(axis=1).groupby('location_id').sum()).loc[location_id],\n",
    "    \n",
    "#     'median pre': (_comp.loc[_idx].median(axis=1).groupby('location_id').sum() \\\n",
    "#                  / _ref.loc[_idx].median(axis=1).groupby('location_id').sum()).loc[location_id],\n",
    "\n",
    "#     'median old way': (_comp.loc[_idx].groupby('location_id').sum().median(axis=1) \\\n",
    "#                  / _ref.loc[_idx].groupby('location_id').sum().median(axis=1)).loc[location_id],\n",
    "    \n",
    "#     'clipped mean post (2.5/97.5)': clipped_mean(_comp, _ref, _idx, [0.025, 0.975]).loc[location_id],\n",
    "    \n",
    "#     'clipped mean post (5/95)': clipped_mean(_comp, _ref, _idx, [0.05, 0.95]).loc[location_id],\n",
    "    \n",
    "#     'median post': (_comp.loc[_idx].groupby('location_id').sum() \\\n",
    "#                     / _ref.loc[_idx].groupby('location_id').sum()).median(axis=1).loc[location_id],\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a00fd49d-e664-425e-a738-33909fe41229",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 23:56:15.183 | INFO     | covid_model_seiir_pipeline.lib.cli_tools.performance_logger.performance_logger:info:26 - Run type: LOCAL\n",
      "2022-12-13 23:56:15.185 | INFO     | covid_model_seiir_pipeline.lib.cli_tools.performance_logger.performance_logger:info:26 - Calculating ratios\n",
      "2022-12-13 23:56:15.187 | INFO     | covid_model_seiir_pipeline.lib.cli_tools.performance_logger.performance_logger:info:26 - ba5\n",
      "2022-12-13 23:57:10.737 | INFO     | covid_model_seiir_pipeline.lib.cli_tools.performance_logger.performance_logger:info:26 - Writing kappa scaling factors\n"
     ]
    }
   ],
   "source": [
    "LOGGER.info(f'Run type: {RUN}')\n",
    "if RUN == 'LOCAL':\n",
    "    LOGGER.info('Calculating ratios')\n",
    "    kappa_scalars = calculate_kappa_scalars(\n",
    "        reference_infections, comparator_infections, sero_points, variants,\n",
    "        units='location_daily_medians',\n",
    "        # units='clipped_location_means',\n",
    "        infections_threshold=0,\n",
    "        minimize_variants=['alpha', 'beta', 'gamma', 'delta'],\n",
    "    )\n",
    "\n",
    "    LOGGER.info('Writing kappa scaling factors')\n",
    "    store_kappa_scalars(kappa_scalars, variants)\n",
    "elif RUN == 'GLOBAL':\n",
    "    LOGGER.info('Calculating ratios')\n",
    "    kappa_scalars = calculate_kappa_scalars(\n",
    "        reference_infections, comparator_infections, sero_points, variants,\n",
    "        units='location_draws',\n",
    "        infections_threshold=1e5,\n",
    "        minimize_variants=[]\n",
    "    )\n",
    "\n",
    "    LOGGER.info('Plotting global distributions')\n",
    "    global_summary = make_histograms(kappa_scalars, variants,\n",
    "                                     sero_locations={\n",
    "                                         'alpha': [\n",
    "                                             # ## ALPHA\n",
    "                                             # 47,    # Czechia\n",
    "                                             # 51,    # Poland\n",
    "                                             # 58,    # Estonia (?)\n",
    "                                             # 545,   # Michigan\n",
    "                                             # 4749,  # England\n",
    "                                             # 434,   # Scotland\n",
    "                                             # 385,   # Puerto Rico (?)\n",
    "                                             # 144,   # Jordan\n",
    "                                             # 180,   # Kenya (?)\n",
    "                                             # 207,   # Ghana (?)\n",
    "                                         ],\n",
    "                                         'beta': [\n",
    "                                             # 181,   # Madagascar (?)\n",
    "                                             # 182,   # Malawi (?)\n",
    "                                             # 196,   # South Africa\n",
    "                                         ],\n",
    "                                         'gamma': [\n",
    "                                             # 98,    # Chile\n",
    "                                             # 4772,  # Rio Grande do Sul (?)\n",
    "                                             # 4775,  # São Paulo\n",
    "                                         ],\n",
    "                                         'delta': [\n",
    "                                             # 89,    # Netherlands (?)\n",
    "                                             # 4749,  # England\n",
    "                                             # 434,   # Scotland\n",
    "                                             # 4646,  # Campeche\n",
    "                                             # 180,   # Kenya (?)\n",
    "                                             # 182,   # Malawi (?)\n",
    "                                             # 196,   # South Africa (?)\n",
    "                                             # 214,   # Nigeria\n",
    "                                         ]\n",
    "                                         # + [state for state in range(4840, 4876)\n",
    "                                         #    if state not in [4840, 4842, 4845, 4850,\n",
    "                                         #                     4847, 4848, 4858, 4861,\n",
    "                                         #                     4862, 4863, 4864, 4866,\n",
    "                                         #                     4869, 4872]]\n",
    "                                         # + list(range(523, 574))\n",
    "                                         ,\n",
    "                                         'omicron': \n",
    "                                             [],\n",
    "                                             # sero_points.index.get_level_values('location_id').unique().to_list(),\n",
    "                                         'ba5': \n",
    "                                             [],\n",
    "                                             # sero_points.index.get_level_values('location_id').unique().to_list(),\n",
    "                                     },)\n",
    "    for variant in variants:\n",
    "        print(variant)\n",
    "        print(global_summary[variant])\n",
    "        print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f719761-9336-477a-a42c-cf212e324175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# omicron (1e5)\n",
    "#                 p25       p50  geom_mean       p75\n",
    "# case       0.152473  0.245849   0.227270  0.367569\n",
    "# admission  0.152440  0.220426   0.223511  0.312732\n",
    "# death      0.112856  0.187334   0.188816  0.325152\n",
    "\n",
    "# omicron (1e6)\n",
    "#                 p25       p50  geom_mean       p75\n",
    "# case       0.165986  0.266392   0.255385  0.398874\n",
    "# admission  0.203510  0.285317   0.304645  0.439119\n",
    "# death      0.145871  0.258278   0.252940  0.435830\n",
    "\n",
    "####################################################\n",
    "\n",
    "# ba5 (1e5)\n",
    "#                 p25       p50  geom_mean       p75\n",
    "# case       0.056931  0.130835   0.109367  0.221797\n",
    "# admission  0.212842  0.412113   0.382877  0.730584\n",
    "# death      0.075324  0.138294   0.135091  0.265208\n",
    "\n",
    "\n",
    "# ba5 (1e6)\n",
    "#                 p25       p50  geom_mean       p75\n",
    "# case       0.077849  0.170130   0.142058  0.243022\n",
    "# admission  0.386437  0.630114   0.576358  0.887026\n",
    "# death      0.086445  0.173559   0.169608  0.326595\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b2912a-31f9-4e95-bcf1-d8514d6473f6",
   "metadata": {},
   "source": [
    "## Pre-omicron global calibration (uses case-based infections to get risk ratios for IHR and IFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba50d7d8-6197-4b85-8473-a7b3b4141e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loader(draw_id: int, version: str, measure: str, columns: List[str]) -> pd.DataFrame:\n",
    "    data = pd.read_parquet(f'{version}/compartments/{measure}_draw_{draw_id}.parquet',\n",
    "                           columns=columns)\n",
    "    data = data.loc[data['round'] == 2].drop('round', axis=1)\n",
    "    data = data.rename(columns={col: col.split('_all_')[1] for col in data})\n",
    "    data = data.groupby(data.columns, axis=1).sum(min_count=1)\n",
    "    data = data.groupby('location_id').diff()\n",
    "    data['draw_id'] = draw_id\n",
    "    data = data.set_index('draw_id', append=True).sort_index()\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_crude_ratio_dist(\n",
    "    measure: str,\n",
    "    prior_variants: List[str],\n",
    "    variant: str,\n",
    "    cf_version: str,\n",
    "    base_version: str,\n",
    "    threshold: int,\n",
    "    n_draws: int = 100,\n",
    "):\n",
    "    columns = [f'Infection_all_{v}_all_lr' for v in prior_variants + [variant]]\n",
    "    columns += [f'Infection_all_{v}_all_hr' for v in prior_variants + [variant]]\n",
    "    columns += ['round']\n",
    "\n",
    "    cf_loader = functools.partial(loader,\n",
    "                                  version=cf_version,\n",
    "                                  measure='case',\n",
    "                                  columns=columns)\n",
    "    daily_cf = parallel.run_parallel(\n",
    "        runner=cf_loader,\n",
    "        arg_list=range(n_draws),\n",
    "        num_cores=NUM_CORES,\n",
    "        progress_bar=False,\n",
    "    )\n",
    "    daily_cf = pd.concat(daily_cf)\n",
    "\n",
    "    base_loader = functools.partial(loader,\n",
    "                                    version=base_version,\n",
    "                                    measure=measure,\n",
    "                                    columns=columns)\n",
    "    daily_base = parallel.run_parallel(\n",
    "        runner=base_loader,\n",
    "        arg_list=range(n_draws),\n",
    "        num_cores=NUM_CORES,\n",
    "        progress_bar=False,\n",
    "    )\n",
    "    daily_base = pd.concat(daily_base)\n",
    "\n",
    "    cumul_cf = daily_cf.groupby(['location_id', 'draw_id']).sum()\n",
    "    cumul_base = daily_base.groupby(['location_id', 'draw_id']).sum()\n",
    "\n",
    "    prior_error = (cumul_base.loc[:, prior_variants].sum(axis=1)\n",
    "                   / cumul_cf.loc[:, prior_variants].sum(axis=1))\n",
    "\n",
    "    error_ratio = cumul_base.loc[:, variant] / (cumul_cf.loc[:, variant] * prior_error)\n",
    "\n",
    "    over_threshold = cumul_cf.loc[:, variant].groupby('location_id').mean() > threshold\n",
    "    threshold_idx = over_threshold.loc[over_threshold].index\n",
    "\n",
    "    subset_error_ratio = (error_ratio\n",
    "                          .loc[threshold_idx]\n",
    "                          .replace(np.inf, np.nan)\n",
    "                          .dropna())\n",
    "    \n",
    "    return subset_error_ratio\n",
    "\n",
    "\n",
    "def evaluate_variant(variant: str, prior_variants: List[str],\n",
    "                     cf_version: str, base_version: str,\n",
    "                     threshold: int):\n",
    "    error_ratio = []\n",
    "    for measure in ['admission', 'death']:\n",
    "        error_ratio.append(\n",
    "            get_crude_ratio_dist(\n",
    "                measure=measure,\n",
    "                prior_variants=prior_variants,\n",
    "                variant=variant,\n",
    "                cf_version=cf_version,\n",
    "                base_version=base_version,\n",
    "                threshold=threshold,\n",
    "            ).rename(measure)\n",
    "        )\n",
    "    error_ratio = pd.concat(error_ratio, axis=1)\n",
    "    LOGGER.info(\n",
    "        '\\n' + '\\n' + variant.upper() + '\\n' +\n",
    "        str(error_ratio.describe().loc[['25%', '50%', 'mean', '75%'], :].T)\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2,figsize=(16, 5))\n",
    "    for i, measure in enumerate(['admission', 'death']):\n",
    "        ax[i].hist(error_ratio[measure].dropna().clip(*np.quantile(error_ratio[measure].dropna(), [0.05, 0.95])).values,\n",
    "                   bins=40)\n",
    "        ax[i].axvline(error_ratio[measure].median(), linestyle='--', color='firebrick')\n",
    "        ax[i].axvline(error_ratio[measure].mean(), linestyle='--', color='mediumseagreen')\n",
    "        ax[i].set_title(measure)\n",
    "    fig.suptitle(variant)\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e3ebbc-7c96-4061-b186-c0050bc82096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for variant in ['alpha', 'beta', 'gamma']:\n",
    "#     evaluate_variant(\n",
    "#         variant=variant,\n",
    "#         prior_variants=['ancestral'],\n",
    "#         cf_version='/ihme/covid-19/seir-fit/2022_10_18.03',\n",
    "#         base_version='/ihme/covid-19/seir-fit/2022_10_18.04',\n",
    "#         threshold=1e5,\n",
    "#     )\n",
    "\n",
    "# evaluate_variant(\n",
    "#     variant='delta',\n",
    "#     prior_variants=['ancestral', 'alpha', 'beta', 'gamma'],\n",
    "#     cf_version='/ihme/covid-19/seir-fit/2022_10_18.05',\n",
    "#     base_version='/ihme/covid-19/seir-fit/2022_10_18.06',\n",
    "#     threshold=1e5,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb0cce8-0128-4239-a8ac-8fb8a29dbf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Full calibration --\n",
    "# Kazakhstan (36)\n",
    "# Kyrgyzstan (37)\n",
    "Alagoas (4751)\n",
    "# Amapá (4753)\n",
    "# Mato Grosso (4762)\n",
    "# Mato Grosso do Sul (4761)\n",
    "# Pará (4763)\n",
    "# Mizoram (4863)\n",
    "# Sikkim (4869)\n",
    "\n",
    "\n",
    "## Broken -- \n",
    "# Qatar (151)\n",
    "# Lakshadweep (4858)\n",
    "# Seychelles (186) [not public, but screws up aggregate]\n",
    "# Central African Republic (169) - splice\n",
    "# Djibouti (177) - splice\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
